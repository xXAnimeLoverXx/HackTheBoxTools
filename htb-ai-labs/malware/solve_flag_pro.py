#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# solve_flag_pro.py — Malimg (25 clases): entrena, evalúa, guarda TorchScript y sube.
import os, sys, time, json, socket, argparse, random
from urllib.parse import urlparse
from collections import Counter

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, WeightedRandomSampler
from torchvision import transforms, datasets, models

import numpy as np
import requests
try:
    from requests_toolbelt import MultipartEncoder, MultipartEncoderMonitor
    _HAS_TOOLBELT = True
except Exception:
    _HAS_TOOLBELT = False

def seed_everything(seed=1337):
    random.seed(seed); torch.manual_seed(seed)

def check_url(url):
    u = urlparse(url)
    if not (u.scheme and u.netloc):
        raise ValueError(f"URL inválida: {url}")
    socket.getaddrinfo(u.hostname, u.port or (443 if u.scheme=='https' else 80))

def compute_class_weights(ds):
    counts = Counter([y for _, y in ds.samples])
    total = sum(counts.values())
    n_classes = len(ds.classes)
    return torch.tensor([total/(n_classes*counts[i]) for i in range(n_classes)], dtype=torch.float32)

class MalwareClassifier(nn.Module):
    def __init__(self, n_classes, hidden=1000, unfreeze="none"):
        super().__init__()
        try:
            weights = models.ResNet50_Weights.DEFAULT
            resnet = models.resnet50(weights=weights)
        except Exception:
            resnet = models.resnet50(weights='DEFAULT')
        in_feats = resnet.fc.in_features
        resnet.fc = nn.Sequential(
            nn.Linear(in_feats, hidden), nn.ReLU(inplace=True), nn.Linear(hidden, n_classes)
        )
        self.backbone = resnet
        for p in self.backbone.parameters():
            p.requires_grad = False
        if unfreeze == "layer4":
            for p in self.backbone.layer4.parameters(): p.requires_grad = True
            for p in self.backbone.fc.parameters(): p.requires_grad = True
        elif unfreeze == "all":
            for p in self.backbone.parameters(): p.requires_grad = True
    def forward(self, x):
        return self.backbone(x)

def make_loaders(base_path, train_bs, test_bs, num_workers=2, balanced_sampler=True):
    tfm = transforms.Compose([
        transforms.Resize((75,75)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])
    ])
    train_ds = datasets.ImageFolder(root=os.path.join(base_path, 'train'), transform=tfm)
    test_ds  = datasets.ImageFolder(root=os.path.join(base_path, 'test'),  transform=tfm)
    if balanced_sampler:
        weights = compute_class_weights(train_ds)
        sample_weights = [weights[y].item() for _, y in train_ds.samples]
        sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)
        train_dl = DataLoader(train_ds, batch_size=train_bs, sampler=sampler, num_workers=num_workers, pin_memory=False)
    else:
        train_dl = DataLoader(train_ds, batch_size=train_bs, shuffle=True, num_workers=num_workers, pin_memory=False)
    test_dl  = DataLoader(test_ds, batch_size=test_bs, shuffle=False, num_workers=num_workers, pin_memory=False)
    return train_dl, test_dl, len(train_ds.classes), train_ds

def build_criterion(label_smoothing=0.0):
    try:
        return nn.CrossEntropyLoss(label_smoothing=max(0.0, label_smoothing))
    except TypeError:
        return nn.CrossEntropyLoss()

def train(model, dl, epochs, device, lr=1e-3, wd=1e-4, label_smoothing=0.0):
    model.to(device)
    crit = build_criterion(label_smoothing)
    opt  = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, weight_decay=wd)
    for ep in range(1, epochs+1):
        model.train(); run_loss=0.0; run_correct=0; n=0; t0=time.time()
        for x,y in dl:
            x,y = x.to(device), y.to(device)
            opt.zero_grad(set_to_none=True)
            logits = model(x)
            loss = crit(logits, y)
            loss.backward(); opt.step()
            run_loss += loss.item()
            _, pred = logits.max(1)
            n += y.size(0); run_correct += (pred==y).sum().item()
        ep_loss = run_loss/max(1,len(dl)); ep_acc=100.0*run_correct/max(1,n)
        print(f"[i] Epoch {ep}: Acc {ep_acc:.2f}% | Loss {ep_loss:.4f} | {int((time.time()-t0)*1000)} ms")

@torch.no_grad()
def evaluate_topk(model, dl, device, k=5):
    model.eval(); model.to(device)
    n1=nk=nt=0
    for x,y in dl:
        x,y = x.to(device), y.to(device)
        logits = model(x)
        _, p1 = logits.max(1)
        n1 += (p1==y).sum().item(); nt += y.size(0)
        if k and k>1:
            topk = torch.topk(logits, k, dim=1).indices
            nk  += sum(y[i].item() in topk[i].tolist() for i in range(y.size(0)))
    top1 = round(100.0*n1/max(1,nt),2); topk_acc = round(100.0*nk/max(1,nt),2) if k and k>1 else None
    return top1, topk_acc

@torch.no_grad()
def confusion_matrix(model, dl, device, n_classes):
    model.eval(); model.to(device)
    cm = torch.zeros((n_classes,n_classes), dtype=torch.int64)
    for x,y in dl:
        x,y = x.to(device), y.to(device)
        logits = model(x)
        preds = logits.argmax(1)
        for t,p in zip(y.view(-1), preds.view(-1)):
            cm[t.long(), p.long()] += 1
    return cm.cpu().numpy()

def save_confusion_png_csv(cm, class_names, out_png='confusion_matrix.png', out_csv='confusion_matrix.csv', normalize=True):
    import numpy as np, matplotlib.pyplot as plt
    mat = cm.astype(np.float64)
    if normalize:
        row = mat.sum(axis=1, keepdims=True)+1e-12
        mat = mat/row
    plt.figure(figsize=(12,10)); im=plt.imshow(mat, interpolation='nearest', aspect='auto')
    plt.title('Confusion Matrix (normalized)'); plt.colorbar(im, fraction=0.046, pad=0.04)
    plt.xlabel('Predicted'); plt.ylabel('True')
    plt.xticks(range(len(class_names)), class_names, rotation=90)
    plt.yticks(range(len(class_names)), class_names)
    plt.tight_layout(); plt.savefig(out_png, dpi=180); plt.close()
    import numpy as np
    np.savetxt(out_csv, cm, fmt='%d', delimiter=',')
    import os
    return os.path.abspath(out_png), os.path.abspath(out_csv)

def save_torchscript(path, model, num_classes, class_to_idx, tfm_info):
    model.eval(); cpu_model = model.to('cpu')
    try:
        scripted = torch.jit.script(cpu_model)
    except Exception:
        example = torch.randn(1,3,75,75)
        scripted = torch.jit.trace(cpu_model, example, strict=False)
    scripted.save(path)
    try:
        with open(path+'.json','w') as f:
            json.dump({"num_classes":num_classes, "class_to_idx":class_to_idx, "transforms":tfm_info}, f)
    except Exception: pass

def upload_streaming(url, filepath, connect_timeout=5, read_timeout=900, max_retries=3, expect_continue=True):
    def _post_toolbelt():
        with open(filepath,'rb') as f:
            enc = MultipartEncoder(fields={"model": (os.path.basename(filepath), f, "application/octet-stream")})
            last = {"b":0}
            def on_chunk(m):
                if m.bytes_read - last["b"] > 2*1024*1024:
                    time.sleep(0.005); last["b"] = m.bytes_read
            mon = MultipartEncoderMonitor(enc, on_chunk)
            headers = {"Content-Type": mon.content_type}
            if expect_continue: headers["Expect"] = "100-continue"
            return requests.post(url, data=mon, headers=headers, timeout=(connect_timeout, read_timeout))
    def _post_plain():
        with open(filepath,'rb') as f:
            headers = {"Expect":"100-continue"} if expect_continue else {}
            return requests.post(url, files={"model": f}, headers=headers, timeout=(connect_timeout, read_timeout))
    post_fn = _HAS_TOOLBELT and _post_toolbelt or _post_plain
    for attempt in range(1, max_retries+1):
        try:
            r = post_fn(); print(f"[*] HTTP {r.status_code}")
            txt = r.text if len(r.text)<4000 else r.text[:4000]+"\n... (truncated)"
            print(txt); r.raise_for_status(); return
        except (requests.exceptions.ReadTimeout, requests.exceptions.ConnectionError) as e:
            print(f"[!] Upload intento {attempt} falló: {e}")
            if attempt==max_retries: raise
            time.sleep(2*attempt)

def main():
    ap = argparse.ArgumentParser(description='HTB Malimg PRO solver')
    ap.add_argument('--data', default='./newdata')
    ap.add_argument('--epochs', type=int, default=8)
    ap.add_argument('--train-batch', type=int, default=512)
    ap.add_argument('--test-batch', type=int, default=1024)
    ap.add_argument('--lr', type=float, default=1e-3)
    ap.add_argument('--weight-decay', type=float, default=1e-4)
    ap.add_argument('--label-smoothing', type=float, default=0.0)
    ap.add_argument('--hidden', type=int, default=1000)
    ap.add_argument('--unfreeze', choices=['none','layer4','all'], default='none')
    ap.add_argument('--seed', type=int, default=1337)
    ap.add_argument('--balanced-sampler', action='store_true')
    ap.add_argument('--no-balanced-sampler', dest='balanced_sampler', action='store_false')
    ap.set_defaults(balanced_sampler=True)
    ap.add_argument('--upload-url', required=True)
    ap.add_argument('--model-out', default='malware_classifier.pt')
    ap.add_argument('--workers', type=int, default=2)
    ap.add_argument('--expect-continue', dest='expect_continue', action='store_true')
    ap.add_argument('--no-expect-continue', dest='expect_continue', action='store_false')
    ap.set_defaults(expect_continue=True)
    ap.add_argument('--connect-timeout', type=int, default=5)
    ap.add_argument('--read-timeout', type=int, default=900)
    args = ap.parse_args()

    seed_everything(args.seed); check_url(args.upload_url)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"[*] Device: {device}")

    train_dl, test_dl, n_classes, train_ds = make_loaders(args.data, args.train_batch, args.test_batch, args.workers, args.balanced_sampler)
    print(f"[*] Nº de clases (dataset): {n_classes}")
    if n_classes != 25:
        print(f"[!] Aviso: el server suele esperar 25 clases; tienes {n_classes}. Asegúrate de usar Malimg completo.")

    model = MalwareClassifier(n_classes, hidden=args.hidden, unfreeze=args.unfreeze)

    print("[*] Entrenando ...")
    train(model, train_dl, args.epochs, device, lr=args.lr, wd=args.weight_decay, label_smoothing=args.label_smoothing)

    print("[*] Evaluando ...")
    top1, top5 = evaluate_topk(model, test_dl, device, k=5)
    print(f"[✓] Test Acc@1: {top1}%")
    if top5 is not None: print(f"[✓] Test Acc@5: {top5}%")

    print("[*] Calculando matriz de confusión ...")
    cm = confusion_matrix(model, test_dl, device, n_classes)
    png_path, csv_path = save_confusion_png_csv(cm, train_ds.classes)
    print(f"[✓] Confusion matrix: {png_path}\n[✓] CSV: {csv_path}")

    print(f"[*] Guardando modelo (TorchScript) en '{args.model_out}' ...")
    tfm_info = {"resize":[75,75], "normalize_mean":[0.485,0.456,0.406], "normalize_std":[0.229,0.224,0.225]}
    save_torchscript(args.model_out, model, n_classes, train_ds.class_to_idx, tfm_info)
    abs_out = os.path.abspath(args.model_out); sz_mb=os.path.getsize(abs_out)/(1024*1024)
    print(f"[✓] Modelo guardado: {abs_out} ({sz_mb:.1f} MB)")

    print(f"[*] Subiendo '{args.model_out}' a '{args.upload_url}' ...")
    upload_streaming(args.upload_url, args.model_out, args.connect_timeout, args.read_timeout, 3, args.expect_continue)

if __name__ == '__main__':
    try:
        main()
    except Exception as e:
        print(f"[X] Error: {e}"); sys.exit(1)
